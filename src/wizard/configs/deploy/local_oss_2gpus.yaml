# @package _global_
# Config for running on workstations with two 40gb+ GPUs, see TUTORIAL
# for extra instructions. In short, use cmd line arg "+deploy=local_2gpus" with wizard.

defaults:
  - /stable_manifest/oss
  - _self_

defines:
  # The repo-relative resolver makes the path relative to the git repo root.
  filesystem: ${repo-relative:"data"}
  nre_cache_size: 4 # nr_concurrent_rollouts + 1
  physics_cache_size: 16  # should match or exceed concurrent unique scenes

services:
  sensorsim:
    environments:
      - OMP_NUM_THREADS=1

      # leave some room for traffic sim if enabled in sub-configs
      # - PYTORCH_CUDA_ALLOC_CONF=garbage_collection_threshold:0.7
    replicas_per_container: 3
    gpus: [1]

  driver:
    replicas_per_container: 3
    gpus: [0]

  physics:
    replicas_per_container: 1
    gpus: [0, 1]

  trafficsim:
    replicas_per_container: 1
    gpus: [0, 1]

  controller:
    replicas_per_container: 6
    gpus: null

runtime:
  nr_workers: 4 # 12 endpoints / 4 workers = 3 endpoints per worker
  endpoints:
    # scaling the number of rollouts assigned to each endpoint to add up
    # # instances x # rollouts = number of rollouts
    # SENS: 1 (nr_gpus)  x 3 (replicas_per_container) x 4 (n_concurrent_rollouts) = 12
    # DRIV: 1 (nr_gpus)  x 3 (replicas_per_container) x 4 (n_concurrent_rollouts) = 12
    # PHYS: 2 (nr_gpus)  x 1 (replicas_per_container) x 6 (n_concurrent_rollouts) = 12
    # CONT: 1 (nr_gpus)  x 6 (replicas_per_container) x 2 (n_concurrent_rollouts) = 12
    sensorsim:
      n_concurrent_rollouts: 4

    driver:
      n_concurrent_rollouts: 4
      skip: false

    physics:
      n_concurrent_rollouts: 6
      skip: false

    controller:
      n_concurrent_rollouts: 2
      skip: false

    trafficsim:
      skip: true
